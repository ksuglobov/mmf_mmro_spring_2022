{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "gd09znn9lvccmt0wd79i86",
    "id": "2KoC0-WJIJoY"
   },
   "source": [
    "# Машинное обучение, ВМК МГУ\n",
    "\n",
    "# Практическое задание 04. Поиск ближайших соседей, обучение метрик, несбалансированные задачи\n",
    "\n",
    "## Общая информация\n",
    "\n",
    "Дата выдачи: 21.04.2022 23:59 MSK\n",
    "\n",
    "Мягкий дедлайн: 08.05.2022 23:59 MSK **(за каждый день просрочки снимается 1 балл)**\n",
    "\n",
    "Жёсткий дедлайн: 15.05.2022 23:59 MSK\n",
    "\n",
    "## Оценивание и штрафы\n",
    "\n",
    "Каждая из задач имеет определенную «стоимость» (указана в скобках около задачи). Максимально допустимая оценка за работу --- **5 баллов + 9 бонусов.**\n",
    "\n",
    "\n",
    "Сдавать задание после указанного жёсткого срока сдачи нельзя. При выставлении неполного балла за задание в связи с наличием ошибок на усмотрение проверяющего предусмотрена возможность исправить работу на указанных в ответном письме условиях.\n",
    "\n",
    "Задание выполняется самостоятельно. «Похожие» решения считаются плагиатом и все задействованные студенты (в том числе те, у кого списали) не могут получить за него больше 0 баллов (подробнее о плагиате см. на странице курса). Если вы нашли решение какого-то из заданий (или его часть) в открытом источнике, необходимо указать ссылку на этот источник в отдельном блоке в конце вашей работы (скорее всего вы будете не единственным, кто это нашел, поэтому чтобы исключить подозрение в плагиате, необходима ссылка на источник).\n",
    "\n",
    "Неэффективная реализация кода может негативно отразиться на оценке.\n",
    "\n",
    "## Формат сдачи\n",
    "\n",
    "Задания сдаются через систему anytask. Посылка должна содержать:\n",
    "\n",
    "* Ноутбук homework-practice-04-knn-imb-Username.ipynb\n",
    "\n",
    "Username — ваша фамилия и имя на латинице именно в таком порядке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "33kmc2ycraisqpws5o19cs"
   },
   "source": [
    "<p style=\"color:#de3815;font-size:25px;\">\n",
    "Напоминание об оформлении и выполнении ноутбука\n",
    "</p>\n",
    "\n",
    "* Все строчки должны быть выполнены. Нужно, чтобы output команды можно было увидеть, не запуская ячейки (кроме редких случаев, когда необходимо намеренно скрыть ненужный output, про такие случаи желательно писать пояснения в тексте). **В противном случае -1 балл**\n",
    "* При оформлении ДЗ нужно пользоваться данным файлом в качестве шаблона. Не нужно удалять и видоизменять написанный код и текст, если явно не указана такая возможность. **В противном случае -1 балл**\n",
    "* В anytask обязательно нужно прикреплять отдельно файл с расширением ipynb (не в архиве, а именно отдельно). Если необходимо отправить еще какие-то файлы, то вынесите их в отдельный архив (если файлов много) и пришлите. **В противном случае -0.5 балла**\n",
    "---\n",
    "* Пишите, пожалуйста, выводы и ответы на вопросы в текстовых ячейках/при помощи print в коде. При их отсутствии мы не можем понять, сделали ли вы задание и понимаете, что происходит, и **поэтому будем снижать баллы**\n",
    "* Если алгоритм не сказано реализовывать явно, его всегда можно импортировать из библиотеки.\n",
    "---\n",
    "* Про графики. _Штрафы будут применяться к каждому результату команды отображения графика (plt.show() и др. аналогичные). Исключением являются графики, генерируемые функциями каких-либо сторонних библиотек, если их нельзя кастомизировать_\n",
    "\n",
    "    * должно быть название (plt.title) графика; **В противном случае &ndash; -0.05 балла**\n",
    "    * на графиках должны быть подписаны оси (plt.xlabel, plt.ylabel); **В противном случае &ndash; -0.025 балла за каждую ось**\n",
    "    * должны быть подписаны единицы измерения (если это возможно); **В противном случае &ndash; -0.025 балла за каждую ось**\n",
    "    * все названия должны быть понятны любому человеку, знакомому с терминологией, без заглядывания в код; **В противном случае &ndash; -0.05 балла**\n",
    "    * подписи тиков на осях не должны сливаться как на одной оси, так и между ними; **В противном случае &ndash; -0.025 балла за каждую ось**\n",
    "    * если изображено несколько сущностей на одном холсте (например несколько функций), то необходима поясняющая легенда (plt.legend); **В противном случае &ndash; -0.05 балла**\n",
    "    * все линии на графиках должны быть чётко видны (нет похожих цветов или цветов, сливающихся с фоном); **В противном случае &ndash; -0.05 балла**\n",
    "    * если отображена величина, имеющая очевидный диапазон значений (например, проценты могут быть от 0 до 100), то желательно масштабировать ось на весь диапазон значений (исключением является случай, когда вам необходимо показать малое отличие, которое незаметно в таких масштабах);\n",
    "    * графики должны быть не супер-микро и не супер-макро по размерам, так, чтобы можно было увидеть все, что нужно.\n",
    "    * при необходимости улучшения наглядности графиков, можно пользоваться логарифмической шкалой по осям x/y.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "nfdkvwdgj3lvlbjrfsbvgi"
   },
   "source": [
    "### Нововведение!\n",
    "\n",
    "* Для удобства поиска вопросов, на которые от вас просят ответа, мы пометили их знаком **(?)**\n",
    "* Знак **(!)** означает, что выполнение замечания необходимо для **возможности получения полного балла**\n",
    "* Даем до +0.3 баллов за выдающиеся успехи по субъективному мнению проверяющих. Этот бонус не апеллируется"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "rs6kwccttj96gszi67zrcd"
   },
   "source": [
    "## Часть 1. Knn, обучение метрик"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "cellId": "5yhqvrat9jprbk1233lkm",
    "id": "n-2MpmJQIK1A"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import sklearn.model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from time import time\n",
    "\n",
    "from sklearn.datasets import make_spd_matrix\n",
    "import scipy.linalg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "jtins7p5lq8lfbp9a624a",
    "id": "zne8FB5jxCpj"
   },
   "source": [
    "Возьмем [датасет](https://www.kaggle.com/delayedkarma/impressionist-classifier-data)  с картинами известных импрессионистов. Работать будем не с самими картинками, а с эмбеддингами картинок, полученных с помощью сверточного классификатора.\n",
    "\n",
    "![](https://storage.googleapis.com/kagglesdsdata/datasets/568245/1031162/training/training/Gauguin/190448.jpg?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=databundle-worker-v2%40kaggle-161607.iam.gserviceaccount.com%2F20210405%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20210405T125358Z&X-Goog-Expires=172799&X-Goog-SignedHeaders=host&X-Goog-Signature=a271b474bf9ec20ba159b951e0ae680fc2b0c694666031f7ea6fc39598172cc55e10f75c12b678b21da9e6bdc20e46886133c219625648b407d2f600eebfdda909b29e0f7f13276d8fea2f8d0480d6298bd98e7f118eb78e8b632fc3d141365356b0e3a2fdd4f09119f99f0907a31da62e8dae7e625e32d831238ecc227b1f5ad2e96a8bfb43d93ef6fe88d7e663e51d387d3550dcad2a7eefc5c941028ba0d7751d18690cf2e26fcdfaa4dacd3dcbb3a4cbb355e62c08b158007b5e764e468cecd3292dae4cfc408e848ecf3e0e5dbe5faa76fcdd77d5370c868583c06e4e3d40c73a7435bd8c32a9803fe6b536e1c6f0791219aadd06120291e937e57c214a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "cellId": "ht5ymgsi2xqyfzu9rcl9j",
    "id": "ZucJvTWFKB5l"
   },
   "outputs": [],
   "source": [
    "X_train = np.load('embeddings/embeds_avpool_train.npy')\n",
    "y_train = np.load('embeddings/labels_avpool_train.npy')\n",
    "X_test = np.load('embeddings/embeds_avpool_test.npy')\n",
    "y_test = np.load('embeddings/labels_avpool_test.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "va9p5yttsqf1rrg8e9f322j",
    "id": "hL0r-ew1xCpk"
   },
   "source": [
    "Будем смотреть на обычную долю верных ответов и на долю верных ответов в топ-3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "cellId": "idtq9t04tje8m2vvfo7m",
    "id": "suK0rywXY_gp"
   },
   "outputs": [],
   "source": [
    "def top_3_accuracy_score(y_true, probas):\n",
    "    preds = np.argsort(probas, axis=1)[:, -3:]\n",
    "    matches = np.zeros_like(y_true)\n",
    "    for i in range(3):\n",
    "        matches += (preds[:, i] == y_true)\n",
    "    return matches.sum() / matches.size\n",
    "\n",
    "def scorer(estimator, X, y):\n",
    "    return accuracy_score(y, estimator.predict(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "02rg7vn4ot82185m124lr9y",
    "id": "czpo3LsVxCpl"
   },
   "source": [
    "**Задание 1. (1 балл)**\n",
    "\n",
    "* **(0.8 балла)** Обучите классификатор k ближайших соседей (из sklearn) на данных, подобрав лучшие гиперпараметры. \n",
    " * Подберите $k$ -- число соседей для kNN\n",
    " * Подберите метрику (параметр metric, поизучате, какие значения туда можно подавать)\n",
    " * **(?)** Какие гиперпараметры получились наилучшими?\n",
    "* **(0.2 балла)** Замерьте качество лучшей модели на обучающей и тестовой выборках.\n",
    "\n",
    "**Подсказки:**\n",
    "* Как и всегда, в таких случаях можно использовать кросс-валидацию (количество фолдов можно положить равным 3..5), либо замерять качество на отдельно выделенной из трейна валидационной выборке. Ну, вы вроде и так должны это все знать ;)\n",
    "* Не забывайте, что кросс-валидацию в некоторых реализациях можно запускать параллельно, что ускорит вычисления (n_jobs=-1)\n",
    "* Обратите внимание, что в функцию top_3_accuracy_score передаются вероятности.\n",
    "\n",
    "**Замечания:**\n",
    "* В качестве целевой метрики нужно брать accuracy (очевидно, но вдруг). \n",
    "* Скорее всего у вас должно получиться сделать кросс-валидацию на декартовом произведении перебираемых параметров (т.е, все возможные комбинации значений). Такой подход будет самым правильным и честным. Если у вас мощности по каким-то причинам не хватает --- то напишите об этом в задании. При этом можно будет реализовать подходы с выбором рандомного подмножества кросс-валидируемых значений, или же перебирать гиперпараметры раздельно (например сначала $k$, потом metric).\n",
    "* **(!)** Переберите хотя бы 50 значений $k$, лежащих на отрезке [1, 100]. Брать диапазон шире не воспрещается :)\n",
    "* **(!)** Переберите хотя бы 3 различные метрики в качестве значения параметра metric\n",
    "\n",
    "\n",
    "**Keywords:**\n",
    "train_test_split, KNeighborsClassifier, GridSearchCV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cellId": "68y81mj2mrj85fhqkr9q9w",
    "id": "UOb-jgKDxCpl"
   },
   "outputs": [],
   "source": [
    "cv = KFold(shuffle=True)\n",
    "# 3 common metrics\n",
    "param = {'n_neighbors': np.arange(1, 116, 2), 'metric': ['euclidean', 'manhattan', 'chebyshev']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "uo2wsbxuvhcn2ulfisnxl"
   },
   "source": [
    "Grid search CV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cellId": "d9margjen9vlypcslt6q19"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=True),\n",
       "             error_score=nan,\n",
       "             estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30,\n",
       "                                            metric='minkowski',\n",
       "                                            metric_params=None, n_jobs=None,\n",
       "                                            n_neighbors=5, p=2,\n",
       "                                            weights='uniform'),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'metric': ['euclidean', 'manhattan', 'chebyshev'],\n",
       "                         'n_neighbors': array([  1,   3,   5,   7,   9,  11,  13,  15,  17,  19,  21,  23,  25,\n",
       "        27,  29,  31,  33,  35,  37,  39,  41,  43,  45,  47,  49,  51,\n",
       "        53,  55,  57,  59,  61,  63,  65,  67,  69,  71,  73,  75,  77,\n",
       "        79,  81,  83,  85,  87,  89,  91,  93,  95,  97,  99, 101, 103,\n",
       "       105, 107, 109, 111, 113, 115])},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search = GridSearchCV(KNeighborsClassifier(), param, cv=cv,\n",
    "                           scoring='accuracy', n_jobs=-1, refit=True)\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "25xnqw0d6v5w07f0c9bvtn"
   },
   "source": [
    "Best:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cellId": "01oohkc6bdwpa80sf3gilc6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.578231651902655,\n",
       " {'metric': 'euclidean', 'n_neighbors': 23},\n",
       " KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='euclidean',\n",
       "                      metric_params=None, n_jobs=None, n_neighbors=23, p=2,\n",
       "                      weights='uniform'))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_score, best_params, best_est = grid_search.best_score_, grid_search.best_params_, grid_search.best_estimator_\n",
    "best_score, best_params, best_est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cellId": "tvyhd9sch4ccozu342lt4w"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scorer (train/test): 0.6268806419257773 /0.5404040404040404\n",
      "top_3_accuracy_score (train/test): 0.89217652958876630.8303030303030303\n"
     ]
    }
   ],
   "source": [
    "print(f'scorer (train/test): {scorer(best_est, X_train, y_train)} /'\n",
    "      f'{scorer(best_est, X_test, y_test)}')\n",
    "\n",
    "print(f'top_3_accuracy_score (train/test): ' \n",
    "      f'{top_3_accuracy_score(y_train, best_est.predict_proba(X_train))}'\n",
    "      f'{top_3_accuracy_score(y_test, best_est.predict_proba(X_test))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "27cl7hszv3mbc11phkfbmn",
    "id": "_TBKfMgLxCpl"
   },
   "source": [
    "**Задание 2. (2 балла)** \n",
    "\n",
    "Теперь будем пользоваться метрикой Махалонобиса.\n",
    "* **(1.4 балла)** Обучите её несколькими методами [отсюда](http://contrib.scikit-learn.org/metric-learn/supervised.html) (для вдохновения можете посмотреть keywords).\n",
    "* **(0.5 балла)** Преобразуйте данные и обучите kNN на них, перебрав только гиперпараметр $k$. Замерьте качество на трейне и тесте.\n",
    "* **(0.1 балла)** **(?)** Какой способ обучения метрики получился наилучшим? **(?)** Как вы думаете, почему?\n",
    "\n",
    "\n",
    "**Подсказка:**\n",
    "* Некоторые методы с дефолтными параметрами учатся очень долго, будьте внимательны.\n",
    "\n",
    "**Замечания:**\n",
    "* **(!)** Рассмотрите хотя бы 3 различных метода обучения метрики.\n",
    "* **(!)** Значения для $k$ берите из предыдущего задания.\n",
    "\n",
    "**Keywords:** make_pipeline, NCA, LMNN, MLKR, ITML_Supervised, LFDA, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "cellId": "hjpm3yd6qhq88zv0mlmlhb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting metric_learn\n",
      "  Downloading metric_learn-0.6.2-py2.py3-none-any.whl (64 kB)\n",
      "     |████████████████████████████████| 64 kB 1.1 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from metric_learn) (1.4.1)\n",
      "Requirement already satisfied: scikit-learn>=0.20.3 in /usr/local/lib/python3.8/dist-packages (from metric_learn) (0.22.1)\n",
      "Requirement already satisfied: numpy in /kernel/fallback/lib/python3.8/site-packages (from metric_learn) (1.19.4)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.20.3->metric_learn) (1.1.0)\n",
      "Installing collected packages: metric-learn\n",
      "Successfully installed metric-learn-0.6.2\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 22.1 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%pip install metric_learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "cellId": "hmwd2rexjxbl7rek2sojc9",
    "id": "9_uXUMeexCpl"
   },
   "outputs": [],
   "source": [
    "from metric_learn import NCA, LMNN, MLKR, ITML_Supervised, LFDA\n",
    "from sklearn.pipeline import Pipeline, make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "cellId": "7pv08re3t5oc2gc6privo"
   },
   "outputs": [],
   "source": [
    "names_arr = ['NCA', 'LMNN', 'LFDA', 'MLKR', 'ITML_Supervised']\n",
    "metric_arr = [NCA(n_components=32), LMNN(n_components=32), LFDA(n_components=32), MLKR(n_components=32), ITML_Supervised(max_iter=250)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "cellId": "zjjyg2ijkylj1xu29fjb8"
   },
   "outputs": [],
   "source": [
    "k = np.arange(1, 116, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "cellId": "c73imncp1avfhs4fb7n9q"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1268de97c9db43739722fe2b77f46074",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NCA, time = 163.33126258850098s\n",
      "best params : {'n_neighbors': 1}\n",
      "scorer (train / test) : 1.0 /0.503030303030303\n",
      "top_3_accuracy_score (train / test) : 1.0, / 0.593939393939394\n",
      "=====\n",
      "LMNN, time = 1585.6841042041779s\n",
      "best params : {'n_neighbors': 7}\n",
      "scorer (train / test) : 0.7186559679037111 /0.5585858585858586\n",
      "top_3_accuracy_score (train / test) : 0.9563691073219659, / 0.796969696969697\n",
      "=====\n",
      "LFDA, time = 20.831985235214233s\n",
      "best params : {'n_neighbors': 93}\n",
      "scorer (train / test) : 0.6933299899699097 /0.6282828282828283\n",
      "top_3_accuracy_score (train / test) : 0.905717151454363, / 0.8575757575757575\n",
      "=====\n",
      "MLKR, time = 1437.7607038021088s\n",
      "best params : {'n_neighbors': 1}\n",
      "scorer (train / test) : 1.0 /0.4777777777777778\n",
      "top_3_accuracy_score (train / test) : 1.0, / 0.5696969696969697\n",
      "=====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python3.8/site-packages/metric_learn/itml.py:35: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  X = np.vstack({tuple(row) for row in pairs.reshape(-1, pairs.shape[2])})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ITML_Supervised, time = 380.5726978778839s\n",
      "best params : {'n_neighbors': 29}\n",
      "scorer (train / test) : 0.6379137412236711 /0.5767676767676768\n",
      "top_3_accuracy_score (train / test) : 0.8964393179538616, / 0.8474747474747475\n",
      "=====\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, metric in tqdm(enumerate(metric_arr)):\n",
    "    start = time()\n",
    "    X_train_tr, X_test_tr = metric.fit_transform(X_train, y_train), metric.transform(X_test)\n",
    "    grid_search = GridSearchCV(KNeighborsClassifier(),\n",
    "                               [{'n_neighbors': k}], cv=cv, scoring='accuracy', n_jobs=-1, refit=True)\n",
    "    grid_search.fit(X_train_tr, y_train)\n",
    "    best_est = grid_search.best_estimator_\n",
    "    time_ = time() - start\n",
    "\n",
    "    print(f'{names_arr[i]}, time = {time_}s')\n",
    "    print(f'best params : {grid_search.best_params_}')\n",
    "    print(f'scorer (train / test) : {scorer(best_est, X_train_tr, y_train)} /'\n",
    "          f'{scorer(best_est, X_test_tr, y_test)}')\n",
    "    train_acc = top_3_accuracy_score(y_train, best_est.predict_proba(X_train_tr))\n",
    "    test_acc = top_3_accuracy_score(y_test, best_est.predict_proba(X_test_tr))\n",
    "    print(f'top_3_accuracy_score (train / test) : {train_acc}, / {test_acc}')\n",
    "    print('=====')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "1s2f5xv9hg1q3uvukdzwv9"
   },
   "source": [
    "Как видно из $accuracy$, лучшим методом оказался LFDA, он имеет наилучшее качество на тесте $\\approx 0.86$. У остальных методов, кроме ITML_Supervised, качество на обучении выше, чем у LFDA. Это свидетельствует о сильном переобучении этих методов. А ITML_supervised немного \"не дотягивает\" до качества LFDA на тесте и имеет качество чуть ниже на обучении, переобучение низкое, если вообще есть."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "wey2khhk0lwerketv6rck",
    "id": "B1i10KyMK9_s"
   },
   "source": [
    "**Задание 3. (1 балл)** \n",
    "\n",
    "Проверьте практически, что будет, если в качестве матрицы в расстоянии Махалонобиса использовать:\n",
    "* **(0.4 балла)** случайную матрицу?\n",
    "* **(0.4 балла)** матрицу ковариаций признаков?\n",
    "* **(0.2 балла)** **(?)** Сделайте выводы, получилось ли хуже (или нет) относительно алгоритмов на наилучших параметров из предыдущего пункта и почему так могло случиться.\n",
    "\n",
    "**Подсказка:**\n",
    "* Напомним, что вычисление метрики Махалонобиса эквивалентно вычислению евклидова расстояния между объектами, к которым применено некоторое линейное преобразование (вспомните семинары). Поэтому можно сразу преобразовывать признаки через линейное преобразование.\n",
    "* Матрицу ковариаций можно считать по отдельному выделенному подмножеству из трейна, а кросс-валидацию делать по оставшемуся трейну\n",
    "\n",
    "**Замечание:**\n",
    "* **(!)** Здесь также в каждом из двух первых пунктов делайте подбор параметра $k$ все по той же сетке, что и ранее.\n",
    "\n",
    "**Keywords:**\n",
    "np.linalg.inv, scipy.linalg.sqrtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "cellId": "81sbxjacfjbqn7wv5swxv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random matrix\n",
      "time = 142.2772183418274\n",
      "best params: {'n_neighbors': 21}\n",
      "scorer (train/test): 0.6140922768304915/0.5404040404040404\n",
      "top_3_accuracy_score (train/test): 0.8856569709127382/0.8121212121212121\n"
     ]
    }
   ],
   "source": [
    "spd_mat = np.linalg.inv(scipy.linalg.sqrtm(make_spd_matrix(X_train.shape[1], random_state=0)))\n",
    "\n",
    "start = time()\n",
    "X_train_tr = X_train @ spd_mat\n",
    "X_test_tr = X_test @ spd_mat\n",
    "\n",
    "grid_search = GridSearchCV(KNeighborsClassifier(), [{'n_neighbors': k}],\n",
    "                           cv=cv, scoring='accuracy', n_jobs=-1, refit=True)\n",
    "grid_search.fit(X_train_tr, y_train)\n",
    "\n",
    "best_est = grid_search.best_estimator_\n",
    "time_ = time() - start\n",
    "\n",
    "print('Random matrix')\n",
    "print(f'time = {time_}')\n",
    "print(f'best params: {grid_search.best_params_}')\n",
    "print(f'scorer (train/test): {scorer(best_est, X_train_tr, y_train)}/{scorer(best_est, X_test_tr, y_test)}')\n",
    "print(f'top_3_accuracy_score (train/test): '\n",
    "      f'{top_3_accuracy_score(y_train, best_est.predict_proba(X_train_tr))}/'\n",
    "      f'{top_3_accuracy_score(y_test, best_est.predict_proba(X_test_tr))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "cellId": "lh1ppjnj5jh8rr6uxhectc"
   },
   "outputs": [],
   "source": [
    "cv = KFold(shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "cellId": "dncha6d1i3b82wjfudjfi6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time = {end}\n",
      "best params: {'n_neighbors': 1}\n",
      "scorer (train/test): 1.0/0.2818181818181818\n",
      "top_3_accuracy_score (train/test): 1.0/0.43636363636363634\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "for train_index, test_index in cv.split(X_train):\n",
    "    ind = train_index.astype('int')\n",
    "    mat = np.linalg.inv(scipy.linalg.sqrtm(np.cov(X_train[ind].T)))\n",
    "    X_train_tr = np.delete(X_train, ind, axis=0) @ mat\n",
    "    X_test_tr = X_test @ mat\n",
    "    break\n",
    "\n",
    "grid_search = GridSearchCV(KNeighborsClassifier(), [{'n_neighbors': k}], cv=cv, scoring='accuracy', n_jobs=-1, refit=True)\n",
    "grid_search.fit(X_train_tr, np.delete(y_train, ind, axis=0))\n",
    "best_est = grid_search.best_estimator_\n",
    "time_ = time() - start\n",
    "\n",
    "print('time = {end}')\n",
    "print(f'best params: {grid_search.best_params_}')\n",
    "print(f'scorer (train/test): {scorer(best_est, X_train_tr, np.delete(y_train, ind, axis=0))}/{scorer(best_est, X_test_tr, y_test)}')\n",
    "print(f'top_3_accuracy_score (train/test): '\n",
    "      f'{top_3_accuracy_score(np.delete(y_train, ind, axis=0), best_est.predict_proba(X_train_tr))}/'\n",
    "      f'{top_3_accuracy_score(y_test, best_est.predict_proba(X_test_tr))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "cellId": "tcsddjvdyupvc24k7adsw"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.28330188679245283"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "9dompiv1igu69z6fpuraqc"
   },
   "source": [
    "* Случайная матрица даёт достаточно хороший результат $\\approx 0.88$ и адекватное число соседей: 21.\n",
    "* Ковариационная матрица даёт плохое качество $\\approx 0.28$, оптимальное число соседей очень мало, вырождено: всего один."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "u7fyfhsuofgctextcrhr99",
    "id": "_QIFy8nkxCpm"
   },
   "source": [
    "**Задание 4. (1 балл + 1 бонус)** \n",
    "\n",
    "* **(0.7 балла)** Обучите какой-нибудь градиентный бустинг на обычных и трансформированных наборах данных\n",
    "* **(0.2 балла)** Замерьте качество на трейне и тесте\n",
    "* **(0.1 балла)** **(?)** Получилось ли увеличить качестве на тесте? **(?)** Почему?\n",
    "\n",
    "**Замечания и бонусные возможности (Б)**\n",
    "* Выбор градиентого бустинга остается за вами. **(Б, 0.5 балла)** При желании и наличии времени, можно рассмотреть несколько различных моделей.\n",
    "* Выбор трансформации данных остается за вами. Рекомендуем выбрать наилучший из тех, которые вы исследовали ранее.\n",
    "* **(Б, 0.5 балла)** При очень сильном желании можно перебрать какие-нибудь параметры у градиентного бустинга."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "cellId": "vcjyaytqqqajjf00krwi4",
    "id": "JvhOwOUZxCpm"
   },
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "cellId": "xlf047l2pyli0eqisrhg1d"
   },
   "outputs": [],
   "source": [
    "X_train_boost, X_val_boost, Y_train_boost, Y_val_boost = train_test_split(X_train, y_train, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "s8603d0zybhe9jzs3i3r"
   },
   "source": [
    "Сделаем перебор по темпу обучения и по количеству деревьев:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "cellId": "0z0uxco1pcur0r9dnped4wqe"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b3bf860f80b47ab946c8cd5e00d918c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e4a7b6b6de74e2299fe10ad45e6d4dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=11.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr = 0.01, n_est = 80\n",
      "scorer (train/test):0.5997850232891436/0.5555555555555556\n",
      "top_3_accuracy_score (train/test): 0.8663561447509853/0.8304093567251462\n",
      "lr = 0.01, n_est = 200\n",
      "scorer (train/test):0.6442135435327839/0.5839598997493735\n",
      "top_3_accuracy_score (train/test): 0.8935865281261197/0.8370927318295739\n",
      "lr = 0.01, n_est = 320\n",
      "scorer (train/test):0.6703690433536367/0.6056808688387636\n",
      "top_3_accuracy_score (train/test): 0.9072017198136868/0.8462823725981621\n",
      "lr = 0.01, n_est = 440\n",
      "scorer (train/test):0.6911501254030813/0.6106934001670844\n",
      "top_3_accuracy_score (train/test): 0.9193837334288786/0.849624060150376\n",
      "lr = 0.01, n_est = 560\n",
      "scorer (train/test):0.7112146184163383/0.6182121971595655\n",
      "top_3_accuracy_score (train/test): 0.9312074525259764/0.8554720133667502\n",
      "lr = 0.01, n_est = 680\n",
      "scorer (train/test):0.7276961662486564/0.6232247284878863\n",
      "top_3_accuracy_score (train/test): 0.9398065209602293/0.858813700918964\n",
      "lr = 0.01, n_est = 800\n",
      "scorer (train/test):0.745969186671444/0.6215538847117794\n",
      "top_3_accuracy_score (train/test): 0.9505553565030455/0.8638262322472848\n",
      "lr = 0.01, n_est = 920\n",
      "scorer (train/test):0.7649587961304192/0.6299081035923141\n",
      "top_3_accuracy_score (train/test): 0.957721246864923/0.8680033416875522\n",
      "lr = 0.01, n_est = 1040\n",
      "scorer (train/test):0.7782156932998925/0.6307435254803676\n",
      "top_3_accuracy_score (train/test): 0.9634539591544249/0.8680033416875522\n",
      "lr = 0.01, n_est = 1160\n",
      "scorer (train/test):0.793980652096023/0.6282372598162071\n",
      "top_3_accuracy_score (train/test): 0.9670369043353637/0.8705096073517126\n",
      "lr = 0.01, n_est = 1280\n",
      "scorer (train/test):0.8065209602293085/0.6290726817042607\n",
      "top_3_accuracy_score (train/test): 0.9709781440343963/0.8696741854636592\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41e66c1c96c2453091f63345b160ef66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=11.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr = 0.046415888336127774, n_est = 80\n",
      "scorer (train/test):0.669294159799355/0.5881370091896407\n",
      "top_3_accuracy_score (train/test): 0.9086348978860623/0.8412698412698413\n",
      "lr = 0.046415888336127774, n_est = 200\n",
      "scorer (train/test):0.7556431386599785/0.620718462823726\n",
      "top_3_accuracy_score (train/test): 0.9570046578287352/0.8654970760233918\n",
      "lr = 0.046415888336127774, n_est = 320\n",
      "scorer (train/test):0.8233608025797206/0.6374269005847953\n",
      "top_3_accuracy_score (train/test): 0.9767108563238982/0.8688387635756056\n",
      "lr = 0.046415888336127774, n_est = 440\n",
      "scorer (train/test):0.8760300967395199/0.6441102756892231\n",
      "top_3_accuracy_score (train/test): 0.9885345754209961/0.87468671679198\n",
      "lr = 0.046415888336127774, n_est = 560\n",
      "scorer (train/test):0.9190254389107847/0.64578111946533\n",
      "top_3_accuracy_score (train/test): 0.9935506986743102/0.8822055137844611\n",
      "lr = 0.046415888336127774, n_est = 680\n",
      "scorer (train/test):0.946255822285919/0.6491228070175439\n",
      "top_3_accuracy_score (train/test): 0.9964170548190613/0.8830409356725146\n",
      "lr = 0.046415888336127774, n_est = 800\n",
      "scorer (train/test):0.9666786098172698/0.6524644945697577\n",
      "top_3_accuracy_score (train/test): 0.9989251164457184/0.8805346700083542\n",
      "lr = 0.046415888336127774, n_est = 920\n",
      "scorer (train/test):0.9810103905410247/0.6516290726817042\n",
      "top_3_accuracy_score (train/test): 0.9992834109638122/0.8805346700083542\n",
      "lr = 0.046415888336127774, n_est = 1040\n",
      "scorer (train/test):0.9917592260838409/0.6466165413533834\n",
      "top_3_accuracy_score (train/test): 0.9996417054819061/0.8822055137844611\n",
      "lr = 0.046415888336127774, n_est = 1160\n",
      "scorer (train/test):0.997133643855249/0.6482873851294904\n",
      "top_3_accuracy_score (train/test): 1.0/0.8830409356725146\n",
      "lr = 0.046415888336127774, n_est = 1280\n",
      "scorer (train/test):0.9989251164457184/0.647451963241437\n",
      "top_3_accuracy_score (train/test): 1.0/0.8822055137844611\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c5f14ee4eaf434b9f039e48b8ee79d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=11.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr = 0.21544346900318834, n_est = 80\n",
      "scorer (train/test):0.8312432819777857/0.6257309941520468\n",
      "top_3_accuracy_score (train/test): 0.9792189179505554/0.873015873015873\n",
      "lr = 0.21544346900318834, n_est = 200\n",
      "scorer (train/test):0.9781440343962737/0.6466165413533834\n",
      "top_3_accuracy_score (train/test): 0.9985668219276245/0.873015873015873\n",
      "lr = 0.21544346900318834, n_est = 320\n",
      "scorer (train/test):0.9989251164457184/0.6416040100250626\n",
      "top_3_accuracy_score (train/test): 1.0/0.8696741854636592\n",
      "lr = 0.21544346900318834, n_est = 440\n",
      "scorer (train/test):1.0/0.6558061821219716\n",
      "top_3_accuracy_score (train/test): 1.0/0.8696741854636592\n",
      "lr = 0.21544346900318834, n_est = 560\n",
      "scorer (train/test):1.0/0.6541353383458647\n",
      "top_3_accuracy_score (train/test): 1.0/0.8771929824561403\n",
      "lr = 0.21544346900318834, n_est = 680\n",
      "scorer (train/test):1.0/0.6574770258980785\n",
      "top_3_accuracy_score (train/test): 1.0/0.873015873015873\n",
      "lr = 0.21544346900318834, n_est = 800\n",
      "scorer (train/test):1.0/0.656641604010025\n",
      "top_3_accuracy_score (train/test): 1.0/0.8713450292397661\n",
      "lr = 0.21544346900318834, n_est = 920\n",
      "scorer (train/test):1.0/0.658312447786132\n",
      "top_3_accuracy_score (train/test): 1.0/0.87468671679198\n",
      "lr = 0.21544346900318834, n_est = 1040\n",
      "scorer (train/test):1.0/0.6599832915622389\n",
      "top_3_accuracy_score (train/test): 1.0/0.8763575605680869\n",
      "lr = 0.21544346900318834, n_est = 1160\n",
      "scorer (train/test):1.0/0.6624895572263994\n",
      "top_3_accuracy_score (train/test): 1.0/0.8771929824561403\n",
      "lr = 0.21544346900318834, n_est = 1280\n",
      "scorer (train/test):1.0/0.658312447786132\n",
      "top_3_accuracy_score (train/test): 1.0/0.8755221386800334\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afc4013b764544cba7d1d8913e0282dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=11.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr = 1.0, n_est = 80\n",
      "scorer (train/test):0.991400931565747/0.5756056808688388\n",
      "top_3_accuracy_score (train/test): 0.9992834109638122/0.8437761069340016\n",
      "lr = 1.0, n_est = 200\n",
      "scorer (train/test):1.0/0.5964912280701754\n",
      "top_3_accuracy_score (train/test): 1.0/0.8571428571428571\n",
      "lr = 1.0, n_est = 320\n",
      "scorer (train/test):1.0/0.6131996658312447\n",
      "top_3_accuracy_score (train/test): 1.0/0.8596491228070176\n",
      "lr = 1.0, n_est = 440\n",
      "scorer (train/test):1.0/0.6198830409356725\n",
      "top_3_accuracy_score (train/test): 1.0/0.860484544695071\n",
      "lr = 1.0, n_est = 560\n",
      "scorer (train/test):1.0/0.6248955722639933\n",
      "top_3_accuracy_score (train/test): 1.0/0.8621553884711779\n",
      "lr = 1.0, n_est = 680\n",
      "scorer (train/test):1.0/0.6240601503759399\n",
      "top_3_accuracy_score (train/test): 1.0/0.8596491228070176\n",
      "lr = 1.0, n_est = 800\n",
      "scorer (train/test):1.0/0.6274018379281537\n",
      "top_3_accuracy_score (train/test): 1.0/0.8596491228070176\n",
      "lr = 1.0, n_est = 920\n",
      "scorer (train/test):1.0/0.6290726817042607\n",
      "top_3_accuracy_score (train/test): 1.0/0.858813700918964\n",
      "lr = 1.0, n_est = 1040\n",
      "scorer (train/test):1.0/0.6265664160401002\n",
      "top_3_accuracy_score (train/test): 1.0/0.8596491228070176\n",
      "lr = 1.0, n_est = 1160\n",
      "scorer (train/test):1.0/0.6290726817042607\n",
      "top_3_accuracy_score (train/test): 1.0/0.8596491228070176\n",
      "lr = 1.0, n_est = 1280\n",
      "scorer (train/test):1.0/0.6324143692564745\n",
      "top_3_accuracy_score (train/test): 1.0/0.8621553884711779\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_arr = np.logspace(-2, 0, num=4)\n",
    "est_arr = np.arange(80, 1400, 120)\n",
    "\n",
    "for lr in tqdm(lr_arr):\n",
    "    for n_est in tqdm(est_arr):\n",
    "        model = CatBoostClassifier(iterations=n_est, learning_rate=lr, verbose=0)\n",
    "        model.fit(X_train_boost, Y_train_boost)\n",
    "        print(f'lr = {lr}, n_est = {n_est}')\n",
    "        print(f'scorer (train/test):'\n",
    "              f'{scorer(model, X_train_boost, Y_train_boost)}/'\n",
    "              f'{scorer(model, X_val_boost, Y_val_boost)}')\n",
    "        print(f'top_3_accuracy_score (train/test): '\n",
    "              f'{top_3_accuracy_score(Y_train_boost, model.predict_proba(X_train_boost))}/'\n",
    "              f'{top_3_accuracy_score(Y_val_boost, model.predict_proba(X_val_boost))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "7br97satw4r5qf31nfvefa",
    "id": "ZpbnT-qSxCpm"
   },
   "source": [
    "**Бонус. (1 балл)**\n",
    "\n",
    "Достигните доли верных ответов 0.75 на тестовой выборке, не используя нейросети.\n",
    "\n",
    "**Замечание:**\n",
    "* Если достигли такого качества где-то раньше в задании, то укажите на это место"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "h0fe2vuxgkhfly10x0z9fp",
    "id": "btaXUkDHxQjk"
   },
   "source": [
    "Достигли по `top_3_accuracy_score` - на пару ячеек выше, в секции про CatBoost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "evib76a838ngikki5o0cl"
   },
   "source": [
    "## Часть 2. Несбалансированные задачи (Все задания из данной части бонусные)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "5dmp2wto46g2hc4u733ljj",
    "id": "MsiB3oacs9BG"
   },
   "source": [
    "В этой части мы разберем основные техники работы в задачах, где один из классов занимает существенно меньшую долю выборки, чем остальные. Для простоты мы обойдемся бинарной задачей, тем не менее, во многом данные методы можно перенести и на задачи с б**о**льшим числом классов. Кроме того, вы получите очередной бесценный опыт исследования библиотеки, заточенной под решение таких задач."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "erfeh72sumpq4ahw4ok8c",
    "id": "I9SXbBCjs9BH"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style='whitegrid')\n",
    "\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "0zz4r8hvg90csp0q3cw0ju",
    "id": "5l0VsXHes9BI"
   },
   "source": [
    "**Задание -1 (1 балл)**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "rbglrdm3g8cffqwfgcxau",
    "id": "SIund96us9BI"
   },
   "source": [
    "В качестве данных для нашей работы возьмем выложенный на kaggle датасет транзакций, в котором нужно выискивать мошеннические проводки: [клик](https://www.kaggle.com/mlg-ulb/creditcardfraud). Данная задача по определению подходит под несбалансированную, что можно сказать даже без наличия каких-либо данных (понятно, что среди всех транзакций клиентов очень малая часть будет мошеннической).\n",
    "\n",
    "Загрузим данные, проведем некоторые классические манипуляции."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "rb1yuelagel3oezaqqi8iz",
    "id": "tY2aKqhCs9BJ"
   },
   "outputs": [],
   "source": [
    "\"\"\"%%bash\n",
    "kaggle datasets download -d mlg-ulb/creditcardfraud\n",
    "unzip creditcardfraud.zip\"\"\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "q0w574t84lelp2iryefr1c",
    "id": "5_UPWW51s9BJ"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "abjkz998n2wtk1oqxtpiss",
    "id": "HpJMyb0Hs9BJ",
    "outputId": "7f254a74-d248-47c6-9550-3e884e3cce92"
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "qn1twgn41kh6h4ltjq66qr",
    "id": "St9c_rxKs9BK"
   },
   "source": [
    "**(0.2 балла)** Наши данные были анонимизированы. Мы имеем 30 признаков, из которых 28 - это результаты PCA-преобразования на исходном датасете. Еще 2 признака представляют собой время в секундах, прошедшее с момента первой транзакции в датасете, и размер транзакции. \n",
    "\n",
    "* **(?)** Скажите (посчитайте), какова доля положительных объектов в выборке?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "tud735t9els7tt6hoirplh",
    "id": "w5P1I6lgs9BL"
   },
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "37cvm2wi8xoeaqu9shs388",
    "id": "eu2TTGCws9BL"
   },
   "source": [
    "**(0.2 балла)** Начнем с обработки времени. Секунды сами по себе не несут большой информации о зависимостях в данных.\n",
    "\n",
    "* Создайте по секундам признаки \"час\" (от 0 до 23) и \"день\" (от 0 до ...) в аналогичной манере (принимая первый объект выборки за начальную точку).\n",
    "* **(?)** Сколько дней покрывают данные?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "02b59kn512wruisjvugzj1",
    "id": "FW414k0js9BL"
   },
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "wk1p9i4kcizrzwniem62",
    "id": "QU5oagixs9BL"
   },
   "source": [
    "**(0.2 балла)**\n",
    "\n",
    "* Постройте следующие графики:\n",
    " 1. Распределение числа транзакций по каждому часу (line-plot).\n",
    " 2. Распределение доли мошеннических транзакций по каждому часу (line-plot)\n",
    " 3. То же самое для дней (здесь можно использовать bar-plot, так как дней должно быть немного).\n",
    "\n",
    "* **(?)** Какие выводы можно сделать из графиков? **(?)** На ваш взгляд, как можно связать полученные нами часы с реальными часами в сутках?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "1uqgyqt53zd48i4i5ax3yu",
    "id": "DGozHHXxs9BM"
   },
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "qyfsnhvg8scedcv94lao",
    "id": "kl7hLlhBs9BM"
   },
   "source": [
    "**(0.2 балла)**\n",
    "\n",
    "С анонимизированными признаками вряд ли можно придумать что-то интересное. \n",
    "\n",
    "* Выберите (например, с помощью корреляции?) несколько наиболее важных признаков и посмотрите на различия в их распределении для разных классов (bar-plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "wwbid53k1n5fn33c7961q",
    "id": "UfFy6Qhys9BM"
   },
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "n8m3s9tqy2rjrz5xfiiqzg",
    "id": "CxCb9nars9BM"
   },
   "source": [
    "**(0.2 балла)**\n",
    "\n",
    "Теперь давайте разделим данные. \n",
    "\n",
    "* Отделите хронологически последние 20% транзакций и поделите их пополам (также хронологически, т.е. без перемешивания) на валидационные и тестовые. Это разбиение не совсем корректно (как можно было заметить, мошеннические транзакции имеют разное распределение во времени - по-хорошему, нам стоило бы выделить целые сутки записей как под валидацию, так и под тест), тем не менее, мы не сможем получить больше данных для адекватного контроля, поэтому обойдемся этим. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "ruics8rzvyqvuoxgirprp",
    "id": "9XXA9XDjs9BN"
   },
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "t4u2nkg0scdms5f01o8cz",
    "id": "h6Gaot3Fs9BN"
   },
   "source": [
    "**Задание 0. (1 балл)**: перед началом работы давайте поговорим о том, как мы будем оценивать качество. Классические метрики для качества классификации чаще всего \"ломаются\" на задачах с сильным перекосом. Чему будет равно значение accuracy для наивного предсказания (= мажорный класс для каждого объекта)? (можете не отвечать, просто подумайте)\n",
    "\n",
    "Из курса МО-1 вам уже известно, что мы можем использовать в таких задачах `AUC-PR` и получать адекватные показатели. Можно сказать, что `AUC-PR` представляет собой матожидание `precision` по распределению, заданному выигрышем в `recall` при смене порога. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "e8udn7waqtw24dmln6jy12",
    "id": "FN144XVps9BO"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "uxycua4exfhohd17jmzkb",
    "id": "haRPLskDs9BO"
   },
   "source": [
    "Тем не менее, существуют и другие, не менее интересные метрики. Одной из таких метрик является коэффициент Каппа Коэна, представляющий собой нормализованную `accuracy`:\n",
    "\n",
    "$$\\kappa = \\frac{p_o - p_e}{1 - p_e}$$\n",
    "\n",
    "Данная метрика служит в качестве меры согласованности между **двумя независимыми предсказателями**, но ничего не знает про \"верные\" и \"предсказанные\" метки (в отличие от многих других метрик машинного обучения). Здесь $p_o$ - доля согласованных предсказаний, а $p_e$ - доля согласованных предсказаний, которая могла бы получиться при случайных ответах предсказателей. В нашем случае это работает так:\n",
    "\n",
    "• В качестве $p_o$ берем accuracy\n",
    "\n",
    "• В качестве $p_e$ примем следующую величину - вероятность случайного соглашения позитивных ответов (произведение долей позитивных ответов в обоих предсказаниях) плюс вероятность случайного соглашения негативных ответов (произведение долей негативных ответов в обоих предсказаниях)\n",
    "\n",
    "Метрика принимает значения от -1 до 1, где 1 - полная согласованность, 0 - согласованность на уровне рандома, -1 - совсем плохо. Как уже говорилось, метрика не различает \"верные\" и \"предсказанные\" метки, поэтому является симметричной (можете использовать это для отладки):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "k9owdyhoevb6hafthqao9r",
    "id": "LC4U_7ays9BO"
   },
   "outputs": [],
   "source": [
    "#для умных\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "#для идейных\n",
    "def samopalnaya_kappa(y1, y2):\n",
    "    po = (y1 == y2).sum() / y1.size\n",
    "    pe = y1.mean() * y2.mean() + (1 - y1.mean()) * (1 - y2.mean())\n",
    "    return (po - pe) / (1 - pe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "8wdc71tse86h6ip36kup6",
    "id": "vldIZwrMs9BP"
   },
   "source": [
    "Еще одной метрикой в такой задаче служит коэффициент корреляции Мэтьюза, выражающийся в терминах матрицы ошибок следующим образом:\n",
    "\n",
    "$$\\text{MCC} = \\frac{TP\\times TN - FP \\times FN}{\\sqrt{(TP+FP)(TP+FN)(TN+FP)(TN+FN)}}$$ \n",
    "\n",
    "Метрика принимает значения от -1 до 1, интерпретируемые аналогичным образом. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "tk0x9ow0risirzwvbzjwc",
    "id": "rsKSZScts9BP"
   },
   "outputs": [],
   "source": [
    "#для умных\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "#для идейных\n",
    "from sklearn.metrics import confusion_matrix\n",
    "def samopalnaya_matthews(y_true, y_pred):\n",
    "    (tn, fp), (fn, tp) = confusion_matrix(y_true, y_pred)\n",
    "    num = tp * tn - fp * fn\n",
    "    denom = np.sqrt((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn))\n",
    "    return num / denom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "66psshab6edahbshfvplef",
    "id": "GaOHYiZPs9BP"
   },
   "source": [
    "**Замечание:**\n",
    "\n",
    "* Обратите внимание, что эти метрики вычисляются на бинаризованных предсказаниях, поэтому может иметь смысл дополнительная настройка порога бинаризации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "5vnd12zj45bkrmdt3ek68o",
    "id": "TBsLuK2ds9BQ"
   },
   "source": [
    "Давайте проверим, что наши метрики (AUC-PR, cohen_kappa, matthews_corrcoef) действительно подходят под задачу. \n",
    "\n",
    "* **(0.2 балла)** Вычислите их значения для наивного предсказания (aka мажорный класс в данных для всех объектов):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "wutwn4zab7mp3icggg9wi",
    "id": "LM_Q37gAs9BQ"
   },
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "04vfs2o1o3hldivzum8z1m6",
    "id": "nwryyw3ts9BQ"
   },
   "source": [
    "Давайте запустим бейзлайн-решение для нашей задачи. С чего же начнем? \n",
    "\n",
    "* **(0.6 балла)** Возьмите `catboost` и обучите его классификатор на наших данных (используйте все признаки).\n",
    "* **(0.2 балла)** Вычислите значения **(!)** **всех 3-x метрик** на тестовой части\n",
    "\n",
    "**Замечание:**\n",
    "* **(!)** Для контроля переобучения используйте валидационную выборку (здесь и далее везде, где фигурирует `catboost`). \n",
    "* **(!)** Необходимо достигнуть качества на тесте >= 0.7 хотя бы на одной из метрик. \n",
    "* **(!)** Необходимо, чтобы значения всех метрик на тесте были >= 0.6\n",
    "\n",
    "**Подсказки:**\n",
    "* Посмотрите на параметр use_best_model у catboost (здесь и далее везде, где фигурирует `catboost`). \n",
    "* И на возможность передавать валидационную выборку через eval_set (здесь и далее везде, где фигурирует `catboost`). \n",
    "* Подбирать гиперпараметры у catboost в этом задании не нужно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "tckm5rgz81b6qp834s1dcj",
    "id": "C3R-MRd7s9BQ"
   },
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "ywn32nzm8jpzdnr9nlfm",
    "id": "ZFFhboVQs9BR"
   },
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "5ytqp86h62dxkocr6pui5",
    "id": "slOmV65fs9BR"
   },
   "source": [
    "**Задание 1. (1 балл)**. Многие реализации методов предлагают встроенные способы для борьбы с нашей проблемой. Самое часто встречающееся решение --- просто добавить вес в функции потерь для минорного класса (таким образом, ошибка на объекте минорного класса будет весить больше, чем для мажорного). В `catboost` это также реализовано, причем для бинарной задачи это можно сделать целыми двумя способами (можете выбрать любой, на свой вкус, автор задания предпочитает отдельный скейлинг для минорного класса). Чаще всего в качестве веса берется отношение числа объектов мажорного класса к числу минорного. \n",
    "\n",
    "* **(0.2 балла)** Обучите модель с таким скалированием\n",
    "* **(0.1 балла)** **(?)** Cравните метрики на тестовой части с бейзлайном (из предыдущего задания)\n",
    "\n",
    "**Keywords:** scale_pos_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "2l0r8qhwm4opxv87u90hj8",
    "id": "WLVjSc0As9BR"
   },
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "pvtzi16q87exj919bqltud",
    "id": "qwhhGSVVs9BR"
   },
   "source": [
    "Поскольку данный вес будет являться гиперпараметром метода, было бы опрометчиво остановиться на одном значении (тем более, с большой вероятностью у вас все сломалось). \n",
    "\n",
    "* **(0.3 балла)** Запустите перебор для этого гиперпараметра на валидационной выборке (используйте `PR-AUC`).\n",
    "* **(0.3 балла)** После этого подберите оптимальный порог бинаризации для $\\kappa$  (aka cohen_kappa) или $\\text{MCC}$ (метрика на ваш выбор).\n",
    "* **(0.1 балла)** Для лучшего найденного веса и порога вычислите все метрики на тестовой части. \n",
    "\n",
    "**Замечание:**\n",
    " * Здесь подбор гиперпараметров можно делать последовательно\n",
    " * Подбирать оптимальное значение можно по валидационной выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "mo5weijgnzls56z0ucreh",
    "id": "LluYkXus8OWt"
   },
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "ctmefwzx3bauja7h1lf1r",
    "id": "6SaQ-j2Ss9BS"
   },
   "source": [
    "**Задание 2. (1 балл)**. На самом деле, то, что мы сейчас делали, очень схоже с другой распространенной техникой - оверсэмплингом. Фактически, мы можем продублировать все объекты минорного класса и получить тот же эффект, какой был бы при использовании веса, равного 2. Тем не менее, такой подход --- это лишь малая часть того, что мы можем проделать с целью повысить число объектов минорного класса. \n",
    "\n",
    "Для продолжения работы установим библиотеку [imbalanced-learn](https://imbalanced-learn.org/stable/):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "1n05csto6ao3fj1bnzm7",
    "id": "oHL5jywds9BS"
   },
   "outputs": [],
   "source": [
    "!pip3 install imbalanced-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "aknvp1w56sn5fxxb1dpmkk",
    "id": "A-dF_oXps9BS"
   },
   "source": [
    "Первый метод, которым мы воспользуемся, называется SMOTE. Кратко его суть такова: мы выбираем случайного кандидата среди $k$ ближайших соседей объекта минорного класса, затем берем точку на отрезке между двумя объектами (т.е. выпуклую комбинацию со случайными коэффициентами) и добавляем в выборку. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "lmyceri7wwf7fsrsil8yp",
    "id": "EcWmeujGs9BS"
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "b83v25l57t7mekfvw3wn9",
    "id": "Pke-fWMGs9BT"
   },
   "source": [
    "* **(0.5 балла)** Используйте SMOTE для ресэмплинга обучающей выборки, на новой выборке обучите модель `catboost` (вес положительных объектов скалировать не нужно).\n",
    "* **(0.1 балла)** Замерьте качество на тестовой выборке\n",
    "* **(0.4 балла)** равните полное выравнивание выборки с частичным (т.е. таким, что баланс классов улучшается, но не достигает равенства - скажем, 1:2 и 1:10).\n",
    "\n",
    "**Замечание:**\n",
    "* **(важно!)** не преобразовывайте валидационную и тестовую выборку никак --- мы не хотим отслеживать качество на объектах, которых в реальности не существует). \n",
    "* В п.3 достаточно рассмотреть одну пару для сравнения.\n",
    "\n",
    "**Keywords:** sampling_strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "2scf5rk6ech5992mvkpbea",
    "id": "xm3HED1ms9BT"
   },
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "wdtfgzfz8ttyuy0tvtd5v",
    "id": "f_3MA21rs9BT"
   },
   "source": [
    "**Бонус (1.5 балла)**. Для vanilla SMOTE существуют некоторые модификации, часть из которых была реализована в библиотеке imblearn. \n",
    "\n",
    "* **(1.2 балла, за каждый метод 0.3)** **(?)** Найдите статьи о следующих методах и попробуйте вкратце сформулировать, в чем их основная идея (сделайте так, чтобы человек, знакомый с машинным обучением в целом, но не слышавший конкретно про это смог понять):\n",
    "\n",
    "BorderlineSMOTE - \n",
    "\n",
    "SVM-SMOTE - \n",
    "\n",
    "K-Means-SMOTE - \n",
    "\n",
    "ADASYN - \n",
    "\n",
    "* **(0.3 балла)** Теперь попробуйте сравнить качество всех методов (обучая при этом `catboost`) на наших данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "n6ujnvqlatggdaigd9bh4",
    "id": "cw5hLd-6s9BT"
   },
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "dg4m6az52i8hha8b6dwnef",
    "id": "xvVG5osbs9BU"
   },
   "source": [
    "**Задание 3. (1 балл)**. До этого момента все наши решения концентрировались на работе с минорным классом. Теперь давайте попробуем зайти с другой стороны. Может быть, для восстановления закономерностей нам не нужно столько объектов мажорного класса, и они просто засоряют нам выборку лишней информацией?\n",
    "\n",
    "Для решения этой проблемы существуют методы андерсэмплинга. Самое простое, что можно придумать --- удалять точки мажорного класса, пока мы не получим приемлемый баланс. \n",
    "\n",
    "* **(0.2 балла)** Протестируйте предлагаемый метод, обучая `catboost`\n",
    "* **(0.2 балла)** Постройте графики (line-plot) достигаемых значений метрик в зависимости от баланса классов и от отношения размеров исходной и пересэмпленной выборки\n",
    "\n",
    "**Замечание:**\n",
    "* Графики можете строить как и в 3d (то есть сразу зависимоть от 2-ух параметров), так и по отдельности в 2d."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "grvysb1hz7d1usbtullppt",
    "id": "GZQymG9Rs9BU"
   },
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "62ira5eyr96yyz08zmso5c",
    "id": "ZRysrdxhs9BU"
   },
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "6jxmvb1rvt21oloa20w5j",
    "id": "w-onGH2ts9BU"
   },
   "source": [
    "Даже такой наивный подход может дать относительно неплохие результаты и улучшить наши метрики. Тем не менее, сейчас мы никак не используем информацию о распределении объектов в выборке. Оказывается, что даже относительно простые эвристические правила могут заметно поднять нам качество --- например, мы можем при отбрасывании использовать близость отдельных объектов мажорного класса к минорному и отбрасывать самые близкие.\n",
    "\n",
    "* **(0.2 балла)** Протестируйте алгоритм [Near-Miss](https://www.site.uottawa.ca/~nat/Workshop2003/jzhang.pdf) на наших данных, обучая `catboost`\n",
    "* **(0.2 балла)** Постройте графики, аналогичные предыдущему пункту\n",
    "* **(0.2 балла)** Также добавьте график с зависимостью качества от числа соседей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "kjyacjy834r2l09v36ciut",
    "id": "FXhxPmEUs9BU"
   },
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import NearMiss\n",
    "\n",
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "3dd8bowwq02ao51yx8xaoj"
   },
   "source": [
    "**Бонус. (0.2 балла)**\n",
    "Расскажите ваши мысли по поводу этого предыдущего задания на ЕМ ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "dtrkg3cwnica2jh80k434e"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ML2 HW KNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Yandex DataSphere Kernel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "notebookId": "bb7e4e01-26df-4a7a-86a3-eb04f0b4c41f",
  "notebookPath": "homework-practice-11-metric-learning-imb.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
